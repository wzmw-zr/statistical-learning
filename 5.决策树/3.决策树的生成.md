# 决策树的生成

## 一、ID3算法

1. ID3算法的核心是在决策树各个节点上应用信息增益准则选择特征，递归地构建决策树。

   具体方法：

   + 从根节点开始，对节点计算所有可能的特征的信息增益;
   + 选择信息增益最大的特征作为节点的特征;
   + 由该特征的不同取值建立子节点;
   + 再对子节点递归地调用以上方法，构建决策树，直到所有的特征信息增益均很小或者没有特征可以选择为止。

   最后得到一棵决策树。

2. ID3算法相当于使用极大似然法进行概率的选择。

3. **ID3算法**：

   + **输入**：训练数据集D，特征集A，阈值$\epsilon$。
   + **输出**：决策树。
   + + 若**D中所有实例属于同一类$C_k$，则T为单节点树**，并将类$C_k$作为该节点的类标记，返回T;
     + 若**$A=\emptyset$，则T为单节点树**，并将D中实例数最大的类$C_k$作为该节点的标记，返回T;
     + 否则，计算A中各个特征对D的信息增益，选择信息增益最大的特征$A_g$;
     + 如果**$A_g$的信息增益小于阈值$\epsilon$，则置T为单节点树**，并将D中实例数最大的类$C_k$作为该节点的类标记，返回T;
     + 否则，对$A_g$的每一个可能值$a_i$，依$A_g=a_i$将D分割为若干非空子集$D_i$，将$D_i$中实例数最大的类作为类标记，构建子节点，由节点及其子节点构成树T，返回T;
     + 对第i个子节点，以$D_i$为训练集，以$A-\{A_g\}$为特征集，递归地调用前5个步骤，得到子树$T_i$，返回$T_i$。

4. ID3算法只有树的生成，所以该算法生成的树很容易产生过拟合。



## 二、C4.5的生成算法

1. C4.5在生成的过程中，用信息增益比来选择特征。
2. **C4.5算法**：
   + **输入**：训练数据集D，特征集A，阈值$\epsilon$。
   + **输出**：决策树T。
   + + 如果D中所有实例属于同一个类$C_k$，则置T为单节点树，并将$C_k$作为该节点的类，返回T;
     + 如果$A=\empty$，则置T为单节点树，并将D中实例数最大的类$C_k$作为该节点的类，返回T;
     + 否则，计算A中各特征对D的信息增益比，选择信息增益比最大的特征$A_g$ ;
     + 如果$A_g$的信息增益比小于阈值$\epsilon$，则置T为单节点树，并将D中实例数最大的类$C_k$作为该节点的类，返回T;
     + 否则，对$A_g$的每一个可能值$a_i$，依$A_g=a_i$将D分割为若干个非空子集$D_i$，将$D_i$中实例数最大的类作为标记，构建子节点，由节点及其子节点构成树T，返回树T;
     + 对节点i，以$D_i$为训练集，以$A-\{A_g\}$为特征集，递归地调用前5步，得到子树$T_i$，返回$T_i$。

