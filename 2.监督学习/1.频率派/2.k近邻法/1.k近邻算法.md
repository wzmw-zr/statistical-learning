# k近邻法

1. + k近邻法(k-nearest neighbor, k-NN)是一种基本分类与回归算法。

   + 分类问题中k近邻法：输入为实例的特征向量，对应于特征空间的点，输出为实例的类别，可以取多类。

   + k近邻法假设给定一个训练数据集，其中的实例类别已定。

     分类时，对新的实例，根据其k个最邻近的训练实例的类别，通过多数表决等方式进行预测。

     因此，**k近邻法不具有显式的学习过程。**

   + k近邻法实际上**利用训练数据集对特征向量空间进行划分，并作为其分类的模型**。

   + k近邻法的**三个基本要素**：**k值的选择、距离度量、分类决策规则**。



## 一、k近邻算法

1. k近邻算法的简要解释：给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的k个实例。这k个实例的多数属于某个类，就把该输入实例分为这个类。

2. **k近邻算法**：

   + **输入**：训练数据集$T=\{(x_1,y_1),(x_2,y_2),...(x_N,y_N)\}$，其中，$x_i \in X \subseteq R^n$为实例的特征向量，$y_i\in Y ={c_1,c_2,...c_K}$为实例的类别，$i=1,2,...N$; 实例特征向量$x$。

   + **输出：**实例x所属的类y。

   + (1) 根据给定的距离度量，在训练集T中找出与x最邻近的k个点，涵盖这k个点的x邻域记作$N_k(x)$。

     (2) 在$N_k(x)$中根据分类决策规则(如多数表决)决定x的类别y。
     $$
     y=\arg \max_{c_j}\sum_{x_i\in N_k(x)}I(y_i=c_j),\quad i=1,2,...N; j=1,2,..K
     $$
     其中$I$为指示函数，即当括号内条件为真时为1,否则为0.

3. k近邻法的特殊情况是k=1的情形，称为最邻近算法。

4. k近邻法没有显式的学习过程。