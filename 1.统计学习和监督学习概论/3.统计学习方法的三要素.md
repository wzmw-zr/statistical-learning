# 统计学习方法的三要素

统计学习方法的三要素：模型、策略、算法。构建一种统计学习方法就是确定具体的统计学习三要素。

## 一、模型

1. 统计学习首要考虑的问题是学习什么样的模型。

2. 在监督学习过程中，模型就是所要学习的条件概率分布或决策函数。模型的假设空间包含所有可能的条件概率分布或决策函数。

3. 假设空间用$F$表示：

   + 假设空间可以定义为决策函数的集合：
     $$
     F=\{f|Y=f(X)\}
     $$
     其中，X和Y是定义在输入空间x和输出空间y上的变量。这时$F$通常是由一个参数向量决定的函数族：
     $$
     F=\{f|Y=f_{\theta}(X),\theta \in R^n\}
     $$
     参数向量$\theta$取值于n维欧式空间$R^n$，称为参数空间(parameter space)。

   + 假设空间也可以定义为条件概率的集合：
     $$
     F=\{P|P(Y|X)\}
     $$
     其中，X和Y是定义在输入空间x和输出空间y上的随机变量。这时$F$通常是由一个参数向量决定的条件概率分布族：
     $$
     F=\{P|P_{\theta}(Y|X),\theta \in R^n\}
     $$
     参数向量取值于n维欧式空间$R^n$，也称为参数空间。



## 二、策略

1. 有了模型的假设空间，统计学习接着需要考虑的是按照什么样的准则学习或者选择最优模型。统计学习的目标在于从假设空间中选取最优模型。
2. 引入损失函数与风险函数的概念：
   + 损失函数度量模型一次预测的好坏。
   + 风险函数度量平均意义下模型预测的好坏。

### (一)损失函数与风险函数

1. 监督学习问题是在假设空间F中选取模型f作为决策函数，对于给定的输入X，由$f(X)$给出相应的输出Y。用一个损失函数(lost function)或代价函数(cost function)来度量输出的预测值$f(X)$和真实值Y之间预测错误的程度。

2. 损失函数是$f(X)$和Y的非负实值函数，记作$L(Y,f(X))$。

3. 统计学习常用的损失函数：

   + 0-1损失函数(0-1 loss function)
     $$
     L(Y,f(X))=\left\{  
                  \begin{array}{**lr**}  
                  1,\qquad Y \neq f(X)\\
                  0,\qquad Y = f(X)
                  \end{array}  
     \right.
     $$

   + 平方损失函数(quadratic loss function)
     $$
     L(Y,f(X))=(Y-f(X))^2
     $$

   + 绝对损失函数(absolute loss function)
     $$
     L(Y,f(X))=|Y-f(X)|
     $$

   + 对数损失函数(logarithmic loss function)或对数似然损失函数(log-likelihood loss function)
     $$
     L(Y,P(Y|X))=-\log P(Y|X)
     $$

   损失函数值越小，模型就越好，对于模型的输入、输出$(X,Y)$是随机变量，遵循联合分布$P(X,Y)$，所以，损失函数的期望是：
   $$
   R_{exp}(f)=E_P[L(Y,f(X))]=\int_{x \times y}L(y,f(x))P(x,y)\mathrm{d}x\mathrm{d}y
   $$
   这是理论上**模型$f(X)$关于联合分布$P(X,Y)$的平均意义下的损失，称为风险函数，或期望损失。**

4. 学习的目标是选择期望风险最小的模型。

5. 由于联合分布$P(X,Y)$是未知的，$R_{exp}(f)$不能直接计算。

   一方面，根据期望风险最小学习模型需要用到联合分布，另一方面，联合分布又是未知的，所以监督学习就成为了一个病态问题 (ill-formed problem)。

6. 给定一个训练数据集
   $$
   T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}
   $$
   **模型$f(X)$关于训练数据集的平均损失称为经验风险(empirical risk)或经验损失(empirical loss)**， 记作$R_{emp}$：
   $$
   R_{emp}(f)=\frac{1}{N}\sum_{i=1}^N L(y_i,f(x_i))
   $$

7. 期望风险$R_{exp}(f)$是模型关于联合分布的期望损失，经验风险$R_{emp}(f)$是模型关于训练样本集的平均损失。

8. 根据大数定律，当样本容量N趋于无穷时，经验风险$R_{exp}(f)$趋于期望风险$R_{emp}(f)$。

   但是实际训练的样本数量无法很大，因此，需要对经验风险进行一定的矫正，这就关系到监督学习的两个基本策略：

   + 经验风险最小化
   + 结构风险最小化



### (二)经验风险最小化与结构风险最小化

1. 经验风险最小化(empirical risk minimization)的策略认为，经验风险最小的模型就是最优的模型。

2. 按照经验风险最小化求最优模型就是求解最优化问题：
   $$
   \min_{f\in F}\frac{1}{N}\sum_{i=1}^N L(y_i,f(x_i))
   $$
   其中F是假设空间。

3. 当样本容量足够大时，经验风险最小化能够保证较好的学习效果。

   但是当样本容量很小时，经验风险最小化会产生“过拟合”(over-fitting)现象。

4. + 结构风险最小化(structure risk minimization)是为了防止过拟合而提出来的策略。

   + 结构风险最小化等价于正则化(regularization)。

   + 结构风险在经验风险上加上表示模型复杂度的正则化项(regularizer)或罚项(penalty term)。

   + 在假设空间，损失函数以及训练数据集确定的情况下，结构风险的定义是：
     $$
     R_{srm}(f)=\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))+\lambda J(f)
     $$
     其中，$J(f)$是模型的复杂度，是定义在假设空间F上的泛函。模型f越复杂，复杂度$J(f)$就越大;反之，模型f越简单，复杂度 $J(f)$就越小。即，复杂度表示了对复杂模型的惩罚。

     $\lambda\ge0$是系数，用以权衡经验风险和模型复杂度。

     结构风险较小需要经验风险和模型复杂度较小。

   + 结构风险最小化策略认为结构风险最小的模型是最优的模型。所以求最优模型，就是求解最优化问题：
     $$
     \min_{f\in F}\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))+\lambda J(f)
     $$

5. 这样，监督学习问题就变成了经验风险或结构风险最优化问题，这时经验风险或者结构风险函数是最优化的目标函数。





## 三、算法

1. 算法是指学习模型的具体计算方法。统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的算法求解最优模型。
2. 此时，统计学习问题归结为最优化问题，统计学习的算法成为求解最优化问题的算法。

