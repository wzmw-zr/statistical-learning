# 监督学习的应用

监督学习的应用主要在三个方面：分类问题，标注问题和回归问题。

## 一、分类问题

1. 在监督学习中，当输出变量Y取有限个离散值时，预测问题就变成了分类问题。

   这时，输入变量X可以是离散的，也可以是连续的。

2. + 监督学习从数据中学习一个**分类模型或分类决策函数**，称为**分类器**(classifier)。

   + 分类器对新的输入进行输出的预测，称为分类(classification)。
   + 可能的输出称为类别(class)。

3. 分类问题包括学习和分类两个过程：

   + 在学习过程中，根据已知的训练数据集利用有效的学习方法学习一个分类器。
     + 在分类过程中，利用学习的分类器对新的输入实例进行分类。
     + 评价分类器性能的指标一般是**分类准确率**，其定义是：**对于给定的测试数据集，分类器正确分类的样本数和总样本数之比**。
     + 分类类别为多个时，称为多分类问题。
     + 对于**二分类问题**常用的评价指标是**精确率**(precision)和**召回率**(recall)。通常以关注的类作为正类，其他类作为负类，分类器在测试数据集上的预测或正确或不正确，有下列4种情况：
       + TP—将正类预测为正类数
       + FN—将正类预测为负类数
       + FP—将负类预测为正类数
       + TN—将负类预测为负类数
     + 精确率定义为$P=\frac{TP}{TP+FP}$
     + 召回率定义为$R=\frac{TP}{TP+FN}$



## 二、标注问题

1. + 标注(tagging)问题也是一个监督学习问题。可以认为标注问题是分类问题的一个推广。
   + 标注问题又是更复杂的**结构预测**(structure prediction)问题的简单形式。
   + 标注问题的输入是一个观测序列，输出是一个标记序列或状态序列。
   + 可能的标记个数是有限的，但是其组合所成的标记序列的个数是依序列长度呈指数级增长的。

2. + 标注问题分为**学习**和**标注**两个过程。

   + 给定一个训练数据集$T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$，这里$x_i=(x_i^{(1)},x_i^{(2)},...,x_i^{(n)})^T，i=1,2,...N$，是输入观测序列; $y_i=(y_i^{(1)},y_i^{(2)},y_i^{(3)},...y_i^{(n)})^T$是相应的输出标记序列。

   + 学习系统基于训练数据集构建一个模型，表示为条件概率分布：
     $$
     P(Y^{(1)},Y^{(2)},..,Y^{(n)}|X^{(1)},X^{(2)},...,X^({n}))
     $$
     这里，每一个$X^{(i)}$取值为所有可能的观测，每一个$Y^{(i)}$取值为所有可能的标记。

   + 标注系统按照学习得到的条件概率分布模型，对新的输入观测序列找到相应的输出标记序列。

   + 具体地，对一个观测序列$x_{N+1}=(x_{N+1}^{(1)},x_{N+1}^{(2)},...x_{N+1}^{(n)})^T$找到条件概率$P((y_{N+1}^{(1)},y_{N+1}^{(2)},...y_{N+1}^{n})^T|(x_{N+1}^{(1)},x_{N+1}^{(2)},...x_{N+1}^{(n)})^T)$最大的标记序列$y_{N+1}=(y_{N+1}^{(1)},y_{N+1}^{(2)},...y_{N+1}^{(n)})^T$。

3. 评价标注模型的指标与评价分类模型的指标一样，常用的有标注准确率，精确率和召回率。

4. 标注常用的统计学习方法有：隐马尔可夫模型，条件随机场。



## 三、回归问题

1. + 回归问题用于预测输入变量(自变量)和输出变量(因变量)之间的关系，特别是当输入变量的值发生变化时，输出变量的值随之发生变化。
   + 回归模型正是表示从输入变量到输出变量之间映射的函数。
   + 回归模型的学习等价于函数拟合，选择一条函数曲线使其很好地你和已知数据且很好地预测未知数据。

2. 回归问题分为学习和预测两个过程。

   + 首先给定一个训练数据集，$T=\{(x_1,y_1),(x_2,y_2),...(x_N,y_N)\}$，这里$x_i \in R^n$是输入，$y \in R$是对应的输出，$i=1,2,...N$。学习系统根据学习的模型$Y=f(X)$确定相应的输出; 对新的输入$X_{N+1}$预测系统根据学习的模型$Y=f(X)$确定相应的输出$y_{N+1}$。

3. 回归问题按照输入变量的个数，分为一元回归和多元回归。

   按照输入变量和输出变量之间的关系的类型即模型的类型，分为线性回归和非线性回归。

4. 回归学习最常用的损失函数是平方损失函数，在此情况下，回归问题可以由最小二乘法(least squares)求解。

