# 模型评估与模型选择

## 一、训练误差与测试误差

1. 当损失函数给定时，**基于损失函数的模型的训练误差(training error)和模型的测试误差(test error)**就自然成为了**学习方法评估的标准**。

   > 统计学习方法具体采用的损失函数未必是评估时使用的损失函数。

2. 假设学习到的模型是$Y=\hat{f}(x)$：

   + **训练误差**是模型$Y=\hat{f}(x)$关于**训练数据集的平均损失**：
     $$
     R_{emp}(\hat{f})=\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))
     $$

   + **测试误差**是模型$Y=\hat{f}(X)$关于**测试数据集的平均损失**：
     $$
     e_{test}=\frac{1}{N^{'}}\sum_{i=1}^{N^{'}}L(y_i,f(x_i))
     $$

   + 测试误差反映了学习方法对未知的测试数据集的预测能力。

   + 通常将学习方法对未知数据的预测能力称为泛化能力(generalization ability)。



## 二、过拟合与模型选择

1. 当假设空间含有不同复杂度(例如，不同的参数个数)的模型时，就要面临模型选择问题。

2. 如果假设空间中存在”真“模型，我们希望选择的模型应该逼近真模型。

   具体地，所选择模型要与真模型的参数个数相同，所选择模型的参数向量与真模型的参数向量相近。

3. + 如果一味地追求提高对训练数据的预测能力，所选模型的复杂度往往会比真模型更高，这种现象称为过拟合。

   + 过拟合是指学习时选择的模型所包含的参数过多，以至出现这一模型对已知的训练数据预测很好，但是对未知的测试数据预测地很差的现象。
   + 模型选择旨在避免过拟合并提高模型的预测能力。

4. 常用的模型选择方法：

   + 正则化
   + 交叉验证



## 三、正则化与交叉验证

### (一)正则化

1. 正则化是结构风险最小化策略策略的实现，在经验风险上加一个正则化项或罚项。

2. 正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。

3. 正则化的一般形式：
   $$
   \min_{f\in F}\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))+\lambda J(f)
   $$
   其中，第1项是经验风险，第2项是正则化项，$\lambda\ge0$是调整两者关系的系数。

   第1项的经验风险较小的模型可能较复杂(有多个非零参数)，这时第2项的模型复杂度会较大。

4. 正则化的作用是选择经验风险和模型复杂度同时较小的模型。

### (二)交叉验证

1. 如果给定的样本数据充足，进行模型选择的一种简单方法是**随机地将数据集分成三部分，分别为训练集(training set)，验证集(validation set)和测试集(test set)。**

2. 训练集用于训练模型，验证集用于模型的选择，测试集用于最终对学习方法的评估。

3. 在学习到的不同复杂度的模型中，选择对验证集有最小预测误差的模型。

4. 对于样本数据不充足的情况，交叉验证的基本想法是重复地使用数据，把给定的数据进行切分，将切分的数据组合为训练集与测试集。

5. 交叉验证的分类：

   + **简单交叉验证**：首先随机地将已给数据分为两部分，一部分作为训练集，另一部分作为测试集;之后用训练集在各种条件下训练模型。在测试集上评价各个模型的测试误差，选出测试误差最小的模型。
   + **S折交叉验证(s-fold cross validation)**：首先随机地旧爱那个已给数据且分为S个互不相交，大小相同的子集，然后利用S - 1个子集的数据训练模型，用余下的子集测试模型。将这一过程对可能的S种选择重复进行，最后选出S次评测中平均测试误差最小的模型。
   + **留一交叉验证**：留一交叉验证往往在数据缺乏的情况下使用，是S折交叉验证的特殊情况，S = N，这里的N是给定的数据集的容量。

   

