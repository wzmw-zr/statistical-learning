# 矩阵运算与深度学习

**深度学习是基于线性代数的**，它使用多层神经网络来解决复杂的问题。**模型的输入、多层神经元权重，激活函数都可以定义为向量(矩阵)**。操作与转换很自然地需要使用神经网络进行训练，同时应用于所有输入。**矩阵及其运算很是和神经网络上的流水线数据流模型。** 输入、权重和函数被视作矩阵，值的流动可以被视作矩阵上的运算。

矩阵运算会用到线性代数和微积分的内容。多数机器学习算法的**反向传播步骤都是基于计算向量和矩阵中的导数来更新值**。而在很多情况下，深度学习中使用$f(\vec{x})$来表示一组$f(x)$形式的函数，比如**矩阵微积分(matrix calculus)**。

## 一、矩阵微积分(matrix calculus)

> 矩阵微积分是微积分在向量中的扩展。	

### 1. 梯度

梯度的定义：$f:R^{m\times n} \rightarrow R$，则函数$f(X)$的梯度是对X中每一个元素求偏导得到的矩阵：
$$
\nabla_Xf(X)\in R^{m\times n}=\left[
\begin{matrix}
\frac{\partial f(X)}{\partial X_{11}} & \frac{\partial f(X)}{\partial X_{12}} & \cdots & \frac{\partial f(X)}{\partial X_{1n}}\\
\frac{\partial f(X)}{\partial X_{21}} & \frac{\partial f(X)}{\partial X_{22}} & \cdots & \frac{\partial f(X)}{\partial X_{2n}}\\
\vdots & \vdots & \ddots & \vdots\\
\frac{\partial f(X)}{\partial X_{m1}} & \frac{\partial f(X)}{\partial X_{m2}} & \cdots & \frac{\partial f(X)}{\partial X_{mn}}\\
\end{matrix}
\right]
$$
或者简写为:
$$
(\nabla_Xf(X))_{ij}=\frac{\partial f(X)}{\partial X_{ij}}
$$

> 根据梯度的定义，只有值域是实数域子集的函数才有梯度。

### 2. Hessian矩阵

函数$f:R^n\rightarrow R$，$f(x)$的Hessian矩阵$H(x)=\nabla_x^2f(x)$:
$$
\nabla_x^2f(x)\in R^{n\times n}=\left[
\begin{matrix}
\frac{\partial^2 f(x)}{\partial x_1^2} & \frac{\partial^2f(x)}{\partial x_1\partial x_2} & \cdots & \frac{\partial^2f(x)}{\partial x_1\partial x_n}\\
\frac{\partial^2 f(x)}{\partial x_2\partial x_1} & \frac{\partial^2f(x)}{\partial x_2^2} & \cdots & \frac{\partial^2f(x)}{\partial x_2\partial x_n}\\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial^2 f(x)}{\partial x_n\partial x_1} & \frac{\partial^2f(x)}{\partial x_n\partial x_2} & \cdots & \frac{\partial^2f(x)}{\partial x_n^2}\\
\end{matrix}
\right]
$$
或者简写为:
$$
(\nabla_x^2f(x))_{ij}=\frac{\partial ^2f(x)}{\partial x_i\partial x_j}
$$
因为
$$
\frac{\partial f(x)}{\partial x_i\partial x_j}=\frac{\partial f(x)}{\partial x_j\partial x_i}
$$
所以Hessian矩阵一定是对称矩阵。

同样的，只有值域是实数集子集的函数才有Hessian矩阵。