# 最大后验估计(Maximum A Posterior, MAP)[贝叶斯估计]

最大后验估计也叫贝叶斯估计，因为涉及后验函数和贝叶斯公式。

**最大后验估计是贝叶斯派的参数估计方法，贝叶斯派认为一切皆随机变量，随机变量的分布函数的参数也是随机变量，对其进行抽样估计时还需要考虑参数的先验分布。**

在贝叶斯派中，似然函数被理解为样本$\boldsymbol{X}=(X_1,X_2,...,X_N)^T$的分布是给定参数$\boldsymbol{\theta}$后的条件分布：
$$
P(\boldsymbol{x_1},\boldsymbol{x_2},...,\boldsymbol{x_N}|\boldsymbol{\theta})=L(\boldsymbol{x_1},\boldsymbol{x_2},...,\boldsymbol{x_N}|\boldsymbol{\theta})=\prod_{i=1}^NP(\boldsymbol{x_i}|\boldsymbol{\theta})
$$
而$\boldsymbol{\theta}$本身也是随机变量，具有先验概率分布函数$P(\boldsymbol{\theta})$。

极大似然估计(贝叶斯估计)的想法是最大化$\boldsymbol{\theta}$的后验概率，应用贝叶斯公式得到：
$$
P(\boldsymbol{\theta}|\boldsymbol{X})=\frac{L(\boldsymbol{X|\theta})P(\boldsymbol{\theta})}{\int_{\theta}L(\boldsymbol{X|\theta})P(\boldsymbol{\theta})\mathrm{d}\theta}
$$
最大后验估计就是要求：
$$
\hat{\boldsymbol{\theta}}=\arg\max_{\boldsymbol{\theta}}P(\boldsymbol{\theta}|\boldsymbol{X})=\arg\max_{\boldsymbol{\theta}}\frac{L(\boldsymbol{X|\theta})P(\boldsymbol{\theta})}{\int_{\theta}L(\boldsymbol{X|\theta})P(\boldsymbol{\theta})\mathrm{d}\theta}
$$
如果不考虑先验概率，那么最大后验概率就变成了极大似然估计。
$$
\hat{\boldsymbol{\theta}}=\arg \max_{\boldsymbol{\theta}}P(\boldsymbol{\theta}|x_1,x_2,...,x_N)=\arg\max_{\boldsymbol{\theta}}P(\boldsymbol{\theta})P(x_i|\boldsymbol{\theta})
$$
**由于在实践中。先验概率$P(\boldsymbol{\theta})$往往不可知，所以极大似然估计用的更多，不过最大后验估计在证明推导中是会用到的。**

> 在机器学习中，有一种和引入先验概率等效的做法，那就是在目标函数(相当于对数似然函数)后面加入正则化项。
>
> 如果加入的是L1正则化，相当于假设了参数的先验分布符合双指数分布，而如果引入了L2正则化，相当于假设了参数的先验分布符合正态分布。
>
> 在机器学习中，**==经验风险最小化和极大似然估计对应，结构风险最小化和贝叶斯估计对应==。**



