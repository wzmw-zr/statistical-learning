# 拉格朗日对偶性(Lagrange duality)

拉格朗日对偶性用于解决约束最优化问题，通过将原始问题转化为对偶问题，解决对偶问题得到原始问题的解。

## 一、原始问题

1. **原始问题**：假设$f(x),c_i(x),h_j(x)$是定义在$R^n$上的**连续可微函数**。考虑约束最优化问题：
   $$
   \min_{x\in R^n} f(x)\\
   \mathrm{s.t.}\quad c_i(x)\le 0,\quad i=1,2,...,k\\
   h_j(x)=0,\quad j=1,2,...,l
   $$
   称此约束最优化问题为原始最优化问题或原始问题。

2. **广义拉格朗日函数**(generalized Lagrange function)：
   $$
   L(x,\alpha, \beta)=f(x)+\sum_{i=1}^k\alpha_ic_i(x)+\sum_{j=1}^l\beta_jh_j(x)
   $$
   这里，$x=(x^{(1)},x^{(2)},...,x^{(n)})^T\in R^n，\alpha_i,\beta_j$是拉格朗日乘子，$\alpha_i\ge0$。考虑x的函数：
   $$
   \theta_P(x)=\max_{\alpha,\beta:\alpha_i\ge0}L(x,\alpha,\beta)
   $$
   这里下标P表示原始问题(primitive problem)。

3. 假设给定某个x。如果x违反原始问题的约束条件，即存在某个i使得$c_i(x)$或者存在某个$j$使得$h_j(x)\neq0$，那么就有：
   $$
   \theta_P(x)=\max_{\alpha,\beta;\alpha_i\ge0}[f(x)+\sum_{i=1}^k\alpha_ic_i(x)+\sum_{j=1}^l\beta_jh_j(x)]=+\infty
   $$
   因为若某个i使约束$c_i(x)>0$，则可令$\alpha_i\rightarrow +\infty$，若某个j使$h_j(x)\neq0$，则可令$\beta_j$使$\beta_jh_j(x)\rightarrow +\infty$，而将其余各$\alpha_i,\beta_j$均取0。

4. 相反地，如果x满足约束条件，则可知$\theta_P(x)=f(x)$。因此，
   $$
   \theta_P(x)=
   \left\{
   \begin{array}{**lr**}  
   f(x),  \quad x满足原始问题约束\\  
   +\infty,  \quad 其他\\  
   \end{array}  
   \right.
   $$
    所以，如果考虑极小化问题
   $$
   \min_x\theta_P(x)=\min_x \max_{\alpha,\beta:\alpha_i\ge0}L(x,\alpha, \beta)
   $$
   这是与原始最优化问题等价的，即它们有相同的解。问题$\min_x \max_{\alpha,\beta:\alpha_i\ge0}$称为广义拉格朗日函数的极小极大问题。

   这样就把原始最优化问题表示为广义拉格朗日函数的极小极大问题。为了方便，定义原始问题的最优值：
   $$
   p^*=\min_x\theta_P(x)
   $$
   称为原始问题的值。



## 二、对偶问题(dual problem)

1. 定义$\theta_D(\alpha, \beta)=\min_xL(x,\alpha,\beta)$，再考虑极大化$\theta_D(\alpha,\beta)=\min_xL(x,\alpha,\beta)$，即
   $$
   \max_{\alpha,\beta:\alpha_i\ge0}\theta_D(\alpha,\beta)=\max_{\alpha,\beta:\alpha_i\ge0}\min_xL(x,\alpha,\beta)
   $$
   问题$\max_{\alpha,\beta:\alpha_i\ge0}\min_xL(x,\alpha,\beta)$称为广义拉格朗日函数的极大极小问题。

2. 可以将广义拉格朗日函数的极大极小问题表示为约束最优化问题：
   $$
   \max_{\alpha,\beta}\theta_D(\alpha,\beta)=\max_{\alpha,\beta}\min_xL(x,\alpha,\beta)\\
   \mathrm{s.t.}\quad a_i\ge 0,\quad i=1,2,...,k
   $$
   称为原始问题的对偶问题，定义对偶问题的最优值
   $$
   d^*=\max_{\alpha,\beta:\alpha_i\ge0}\theta_D(\alpha,\beta)
   $$
   称为对偶问题的值。



## 三、原问题与对偶问题的关系

1. **定理**：若原始问题和对偶问题都有最优值，则
   $$
   d^*=\max_{\alpha,\beta:\alpha_i\ge0}\min_x L(x,\alpha,\beta)\le\min_x\max_{\alpha,\beta:\alpha_i\ge0}L(x,\alpha,\beta)=p^*
   $$
   **证明**：对任意的$\alpha,\beta$和x，有
   $$
   \theta_D(\alpha,\beta)=\min_xL(x,\alpha,\beta)\le\min_x\max_{\alpha,\beta:\alpha_i\ge0}L(x,\alpha,\beta)=\theta_P(x)
   $$
   即$\theta_D(\alpha,\beta)\le\theta_P(x)$，由于原始问题和对偶问题都有最优值，所以，
   $$
   \max_{\alpha,\beta:\alpha_i\ge0}\theta_D(\alpha,\beta)\le\min_x\theta_P(x)
   $$
   即:
   $$
   d^*=\max_{\alpha,\beta:\alpha_i\ge0}\min_x L(x,\alpha,\beta)\le\min_x\max_{\alpha,\beta:\alpha_i\ge0}L(x,\alpha,\beta)=p^*
   $$

2. **推论1**：设$x^*$和$\alpha^*,\beta^*$分别是原始问题和对偶问题的可行解，且$d^*=p^*$，则$x^*$和$\alpha^*,\beta^*$分别是原始问题和对偶问题的最优解。

3. **定理2**：考虑原始问题和对偶问题。假设函数$f(x)$和$c_i(x)$是凸函数，$h_j(x)$是仿射函数，并且假设不等是约束$c_i(x)$是严格执行的，即存在$x$，对所有i有$c_i(x)<0$，则存在$x^*,\alpha^*,\beta^*$，使$x^*$是原始问题的解，$\alpha^*,\beta^*$是对偶问题的解，并且$p^*=b^*=L(x^*,\alpha^*,\beta^*)$。

4. **定理3**：对原始问题和对偶问题，假设函数$f(x)$和$c_i(x)$是凸函数，$h_j(x)$是仿射函数，并且不等式约束$c_i(x)$是严格执行的，则$x^*$和$\alpha^*,\beta^*$分别是原始问题和对偶问题的解的充分必要条件是$x^*,\alpha^*,\beta^*$满足下面的Karush-Kuhn-Tucker(KTT)条件：
   $$
   \nabla_xL(x^*,\alpha^*,\beta^*)=0\\
   \alpha_i^*c_i(x^*)=0,\quad i=1,2,...,k\\
   c_i(x^*)\le0,\quad i=1,2,...,k\\
   \alpha_i^*\ge0,\quad i=1,2,...,k\\
   h_j(x^*)=0,\quad j=1,2,...,l
   $$
   由此条件可知：若$\alpha^*>0$，则$c_i(x^*)=0$。