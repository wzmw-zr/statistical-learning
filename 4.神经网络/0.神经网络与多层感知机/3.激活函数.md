# 激活函数

## 一、为什么需要激活函数

如果没有激活函数，那么网络退化为单层网络。

隐藏层加入激活函数，可避免网络退化。

让多层感知机成为真正的多层，否则等价于一层

引入非线性，使网络可以逼近任意非线性函数(万能逼近定理， universal approximator)。

激活函数需要具备的性质：

+ 连续并可导(允许少数点上不可导)，便于利用数值优化的方法来学习网络参数(反向传播算法就是用来求偏微分的)。
+ 激活函数及其导函数要尽可能的简单，有利于提高网络计算效率。
+ 激活函数的导函数的值域要在合适的区间内，不能太大也不能太小，否则会影响训练的效率和稳定性。

常见的激活函数：Sigmod(S型)，Tanh(双曲正切)[饱和激活函数]，ReLU(非线性修正单元)[非饱和激活函数]。