# 权值初始化(Weight Initialization)

## 一、权值初始化

1. **权值初始化**：训练前对权值参数赋值，良好的权值初始化有利于模型训练。

   > **将所有W初始化为0是错误的**。因为如果所有的参数都是0，那么所有神经元的输出都将是相同的，那在back propagation的时候同一层内所有神经元的行为也是相同的 --- gradient相同，weight update也相同。这显然是一个不可接受的结果。

2. **随机初始化法**：高斯分布随机初始化，从高斯分布中随机采样，对权重进行赋值。

   > 权重不能太大，也不能太小。

3. **自适应标准差**：自适应方法随机分布中的标准差。

   较好的自适应标准差方法有：Xavier初始化，He初始化，Kaiming初始化(MSRA)等。



## 二、Xavier初始化

1. Xavier初始化的思想：**为了使得网络中信息更好的流动，每一层输出的方差应该尽量相等。**

   因此，Xavier需要考虑输入神经元的个数与输出神经元的个数。

2. Xavier初始化近似为均匀分布：
   $$
   W\sim U[-\sqrt{\frac{6}{n_j+n_{j+1}}},\sqrt{\frac{6}{n_j+n_{j+1}}}]
   $$
   $n_j$是输入神经元的个数，$n_{j+1}$是输出神经元的个数。

